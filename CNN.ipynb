{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6eeab7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Embedding, Conv1D, MaxPooling1D, Flatten\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7a378ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the reviews and labels from the file\n",
    "with open('train_reviews.pkl', 'rb') as f:\n",
    "    train_reviews, train_labels = pickle.load(f)\n",
    "\n",
    "with open('test_reviews.pkl', 'rb') as f:\n",
    "    test_reviews, test_labels = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b74d7eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tokenized and padded sequences\n",
    "x_train = np.load('x_train.npy')\n",
    "x_test = np.load('x_test.npy')\n",
    "\n",
    "# Load the one-hot encoded labels\n",
    "y_train = np.load('y_train.npy')\n",
    "y_test = np.load('y_test.npy')\n",
    "\n",
    "# Load the tokenizer\n",
    "with open('tokenizer.pkl', 'rb') as f:\n",
    "    tokenizer = pickle.load(f)\n",
    "\n",
    "max_words = 10000\n",
    "max_review_length = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe99c3e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - accuracy: 0.6454 - loss: 0.5773\n",
      "Epoch 2/5\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.9322 - loss: 0.1825\n",
      "Epoch 3/5\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.9583 - loss: 0.1215\n",
      "Epoch 4/5\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.9794 - loss: 0.0702\n",
      "Epoch 5/5\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 25ms/step - accuracy: 0.9919 - loss: 0.0384\n"
     ]
    }
   ],
   "source": [
    "# Define the CNN model architecture\n",
    "embedding_vector_length = 32\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words, embedding_vector_length, input_length=max_review_length))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, epochs=5, batch_size=64)\n",
    "\n",
    "# Save the model\n",
    "model.save('CNN_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "814144ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model = load_model('CNN_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07755513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step\n",
      "Accuracy: 0.87\n",
      "Precision: 0.88\n",
      "Recall: 0.86\n",
      "F1 Score: 0.87\n"
     ]
    }
   ],
   "source": [
    "# Predict the test set\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Convert predictions to class labels\n",
    "y_pred_labels = [1 if pred[1] > pred[0] else 0 for pred in y_pred]\n",
    "\n",
    "# Calculate and print accuracy, precision, recall, and F1 score\n",
    "accuracy = accuracy_score(test_labels, y_pred_labels)\n",
    "precision = precision_score(test_labels, y_pred_labels)\n",
    "recall = recall_score(test_labels, y_pred_labels)\n",
    "f1 = f1_score(test_labels, y_pred_labels)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88c3413a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a review: I'm not a big fan of musicals, although this technically might not qualify as a musical. But I thought I would give it a chance as I love war movies. It was mediocre at best.<br /><br />Hudson seems totally out of kilter in this role. It just didn't work for me. Julie Andrews probably played her part as best as she could, but I just find it hard to buy her as a conniving, deceptive spy. Sorry, I know that is classic stereotyping on my part. But I have to say I think this is Julie at her most beautiful and feminine looking. I always thought of her as more matronly, but then surely that's a result of her roles in Sound of Music and Mary Poppins. No doubt they were desperately trying to get her out of that typecasting in this role. She was quite beguiling in appearance here, but I still didn't buy her as a spy.<br /><br />I couldn't keep my focus through the whole movie and found myself tuning in and out - and having conversations with those in my room (which I usually never do - I'm always shushing everybody). So that tells you how little it held my attention. Don't waste your time!\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "The predicted sentiment for the review is: negative\n"
     ]
    }
   ],
   "source": [
    "# Take user input for the review\n",
    "input_review = input(\"Enter a review: \")\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_review(review, tokenizer, maxlen):\n",
    "    # Convert the review to a sequence of integers\n",
    "    sequences = tokenizer.texts_to_sequences([review])\n",
    "    # Pad the sequences to ensure uniform input length\n",
    "    padded_sequences = pad_sequences(sequences, maxlen=maxlen)\n",
    "    return padded_sequences\n",
    "\n",
    "# Preprocess the input review\n",
    "preprocessed_review = preprocess_review(input_review, tokenizer, max_review_length)\n",
    "\n",
    "# Predict the sentiment of the input review\n",
    "y_pred = model.predict(preprocessed_review)\n",
    "\n",
    "# Convert prediction to class label (1 for positive, 0 for negative)\n",
    "y_pred_label = 1 if y_pred[0][1] > y_pred[0][0] else 0\n",
    "\n",
    "# Print the predicted sentiment\n",
    "sentiment = \"positive\" if y_pred_label == 1 else \"negative\"\n",
    "print(f\"The predicted sentiment for the review is: {sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a446192",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
