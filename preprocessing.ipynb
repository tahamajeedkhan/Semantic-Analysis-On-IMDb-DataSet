{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa2db44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fed1d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the paths to dataset\n",
    "train_dir_pos = 'aclImdb/train/pos'\n",
    "train_dir_neg = 'aclImdb/train/neg'\n",
    "train_dir_unsup = 'aclImdb/train/unsup'\n",
    "test_dir_pos = 'aclImdb/test/pos'\n",
    "test_dir_neg = 'aclImdb/test/neg'\n",
    "\n",
    "# Function to load the positive reviews\n",
    "def load_data_pos(dir):\n",
    "    reviews = []\n",
    "    labels = []\n",
    "    # Load positive reviews\n",
    "    for fname in os.listdir(dir):\n",
    "        if fname.endswith('.txt'):\n",
    "            with open(os.path.join(dir, fname), encoding='utf-8') as f:\n",
    "                review = f.read()\n",
    "                reviews.append(review)\n",
    "                labels.append(1)\n",
    "    return reviews, labels\n",
    "\n",
    "# Function to load the negative reviews\n",
    "def load_data_neg(dir):\n",
    "    reviews = []\n",
    "    labels = []\n",
    "    # Load negative reviews\n",
    "    for fname in os.listdir(dir):\n",
    "        if fname.endswith('.txt'):\n",
    "            with open(os.path.join(dir, fname), encoding='utf-8') as f:\n",
    "                review = f.read()\n",
    "                reviews.append(review)\n",
    "                labels.append(0)\n",
    "    return reviews, labels\n",
    "\n",
    "# Function to load the unsupervised reviews\n",
    "def load_unsupervised_data(dir):\n",
    "    reviews = []\n",
    "    for fname in os.listdir(dir):\n",
    "        if fname.endswith('.txt'):\n",
    "            with open(os.path.join(dir, fname), encoding='utf-8') as f:\n",
    "                review = f.read()\n",
    "                reviews.append(review)\n",
    "    return reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a261f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "train_reviews_pos, train_labels_pos = load_data_pos(train_dir_pos)\n",
    "train_reviews_neg, train_labels_neg = load_data_neg(train_dir_neg)\n",
    "train_reviews = train_reviews_pos + train_reviews_neg\n",
    "train_labels = train_labels_pos + train_labels_neg\n",
    "\n",
    "# Load testing data\n",
    "test_reviews_pos, test_labels_pos = load_data_pos(test_dir_pos)\n",
    "test_reviews_neg, test_labels_neg = load_data_neg(test_dir_neg)\n",
    "test_reviews = test_reviews_pos + test_reviews_neg\n",
    "test_labels = test_labels_pos + test_labels_neg\n",
    "\n",
    "# Save the reviews and labels to a file\n",
    "with open('train_reviews.pkl', 'wb') as f:\n",
    "    pickle.dump((train_reviews, train_labels), f)\n",
    "\n",
    "with open('test_reviews.pkl', 'wb') as f:\n",
    "    pickle.dump((test_reviews, test_labels), f)\n",
    "\n",
    "# Load unsupervised reviews\n",
    "unsup_reviews = load_unsupervised_data(train_dir_unsup)\n",
    "\n",
    "with open('unsup_reviews.pkl', 'wb') as f:\n",
    "     pickle.dump(unsup_reviews, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc7d4313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the reviews\n",
    "max_words = 10000\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(train_reviews)\n",
    "x_train = tokenizer.texts_to_sequences(train_reviews)\n",
    "x_test = tokenizer.texts_to_sequences(test_reviews)\n",
    "\n",
    "# Pad sequences to a maximum review length\n",
    "max_review_length = 500\n",
    "x_train = pad_sequences(x_train, maxlen=max_review_length)\n",
    "x_test = pad_sequences(x_test, maxlen=max_review_length)\n",
    "\n",
    "# One-hot encode the labels\n",
    "y_train = to_categorical(train_labels)\n",
    "y_test = to_categorical(test_labels)\n",
    "\n",
    "# Save the tokenized and padded sequences\n",
    "np.save('x_train.npy', x_train)\n",
    "np.save('x_test.npy', x_test)\n",
    "\n",
    "# Save the one-hot encoded labels\n",
    "np.save('y_train.npy', y_train)\n",
    "np.save('y_test.npy', y_test)\n",
    "\n",
    "# Save the tokenizer\n",
    "with open('tokenizer.pkl', 'wb') as f:\n",
    "    pickle.dump(tokenizer, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55205ad0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
